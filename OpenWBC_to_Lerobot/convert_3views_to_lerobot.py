#!/usr/bin/env python3
"""
å°†OpenWBCæ ¼å¼çš„æ•°æ®é›†è½¬æ¢ä¸ºLeRobotæ ¼å¼ï¼ˆæ”¯æŒå¤šè§†è§’ï¼‰

ç”¨æ³•:
python convert_3views_to_lerobot.py \
    --input_dir /path/to/input \
    --output_dir ./lerobot_dataset \
    --dataset_name "pick_cola" \
    --robot_type "g1" \
    --fps 30
"""

import argparse
import json
import os
from pathlib import Path
import shutil
import tempfile
from typing import Dict, List, Any, Tuple
import numpy as np
import pandas as pd
import cv2
from tqdm import tqdm
import ast

# å®šä¹‰ç›¸æœºè§†è§’æ˜ å°„
VIEW_MAPPING = {
    0: "ego_view",      # å¤´éƒ¨ç›¸æœº
    1: "wrist_left",    # å·¦æ‰‹è…•ç›¸æœº
    2: "wrist_right"    # å³æ‰‹è…•ç›¸æœº
}

def parse_json_data(json_file: Path) -> Dict[str, Any]:
    """è§£ædata.jsonæ–‡ä»¶"""
    print(f"è§£ææ–‡ä»¶: {json_file}")
    with open(json_file, 'r') as f:
        data = json.load(f)
    return data

def extract_state_vector(states_dict):
    """ä»stateså­—å…¸ä¸­æå–40ç»´çŠ¶æ€å‘é‡"""
    state_parts = []
    
    # left_arm qpos (7ç»´)
    if 'left_arm' in states_dict and 'qpos' in states_dict['left_arm']:
        state_parts.extend(states_dict['left_arm']['qpos'])
    
    # right_arm qpos (7ç»´)  
    if 'right_arm' in states_dict and 'qpos' in states_dict['right_arm']:
        state_parts.extend(states_dict['right_arm']['qpos'])
    
    # left_hand qpos (7ç»´)
    if 'left_hand' in states_dict and 'qpos' in states_dict['left_hand']:
        state_parts.extend(states_dict['left_hand']['qpos'])
    
    # right_hand qpos (7ç»´)
    if 'right_hand' in states_dict and 'qpos' in states_dict['right_hand']:
        state_parts.extend(states_dict['right_hand']['qpos'])
    
    # left_leg qpos (6ç»´)
    if 'left_leg' in states_dict and 'qpos' in states_dict['left_leg']:
        state_parts.extend(states_dict['left_leg']['qpos'])
    
    # right_leg qpos (6ç»´)
    if 'right_leg' in states_dict and 'qpos' in states_dict['right_leg']:
        state_parts.extend(states_dict['right_leg']['qpos'])
    
    return np.array(state_parts, dtype=np.float64)

def extract_action_vector(actions_dict):
    """ä»actionså­—å…¸ä¸­æå–32ç»´åŠ¨ä½œå‘é‡"""
    action_parts = []
    
    # left_arm qpos (7ç»´)
    if 'left_arm' in actions_dict and 'qpos' in actions_dict['left_arm']:
        action_parts.extend(actions_dict['left_arm']['qpos'])
    
    # right_arm qpos (7ç»´)
    if 'right_arm' in actions_dict and 'qpos' in actions_dict['right_arm']:
        action_parts.extend(actions_dict['right_arm']['qpos'])
    
    # left_hand qpos (7ç»´)
    if 'left_hand' in actions_dict and 'qpos' in actions_dict['left_hand']:
        action_parts.extend(actions_dict['left_hand']['qpos'])
    
    # right_hand qpos (7ç»´)
    if 'right_hand' in actions_dict and 'qpos' in actions_dict['right_hand']:
        action_parts.extend(actions_dict['right_hand']['qpos'])
    
    # controller command (4ç»´)
    if 'left_leg' in actions_dict and 'qpos' in actions_dict['left_leg']:
        controller_cmd = actions_dict['left_leg']['qpos']
        if isinstance(controller_cmd[0], list):
            controller_cmd = controller_cmd[0]
        action_parts.extend(controller_cmd)
    
    return np.array(action_parts, dtype=np.float64)

def convert_episode(input_episode_dir: Path, episode_idx: int, output_dir: Path, fps: float, task_map: Dict[str, int] = None) -> Dict[str, Any]:
    """è½¬æ¢å•ä¸ªepisode"""
    print(f"è½¬æ¢episode {episode_idx}...")
    
    # è¯»å–JSONæ•°æ®
    json_path = input_episode_dir / "data.json"
    if not json_path.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°data.jsonæ–‡ä»¶: {json_path}")
    
    episode_data = parse_json_data(json_path)
    
    # æ£€æŸ¥å¿…è¦çš„å­—æ®µ
    if "data" not in episode_data:
        raise ValueError(f"Episode {episode_idx}: data.jsonç¼ºå°‘dataå­—æ®µ")
    
    data_frames = episode_data["data"]
    task_info = episode_data.get("text", {})
    
    # åˆ›å»ºepisodeæ•°æ®
    episode_length = len(data_frames)
    frames_data = []
    
    for frame_idx, frame_data in enumerate(data_frames):
        # ç¡®å®štask_index
        task_description = task_info.get("goal", "default_task") if task_info else "default_task"
        current_task_index = task_map.get(task_description, 0) if task_map else 0
        
        processed_frame = {
            "episode_index": episode_idx,
            "frame_index": frame_idx,
            "timestamp": frame_idx / fps,
            "task_index": current_task_index,
        }
        
        # æ·»åŠ statesæ•°æ®
        if "states" in frame_data and frame_data["states"]:
            states = frame_data["states"]
            if isinstance(states, dict):
                if "left_arm" in states:
                    processed_frame["observation.state"] = extract_state_vector(states)
                else:
                    processed_frame["observation.state"] = extract_state_vector(states)
            else:
                processed_frame["observation.state"] = extract_state_vector(states)
        
        # æ·»åŠ actionæ•°æ®
        if "actions" in frame_data and frame_data["actions"]:
            actions = frame_data["actions"]
            if isinstance(actions, dict):
                if "left_arm" in actions:
                    processed_frame["action"] = extract_action_vector(actions)
                else:
                    processed_frame["action"] = extract_action_vector(actions)
            else:
                processed_frame["action"] = extract_action_vector(actions)
        
        # æ·»åŠ episodeç»“æŸæ ‡å¿—å’Œnext.reward
        processed_frame["next.done"] = frame_idx == episode_length - 1
        processed_frame["next.reward"] = 0.0
        
        # æ·»åŠ ä»»åŠ¡æè¿°ç›¸å…³å­—æ®µ
        if task_info and "goal" in task_info:
            processed_frame["annotation.human.action.task_description"] = current_task_index
        
        # æ·»åŠ æ ‡æ³¨æœ‰æ•ˆæ€§å­—æ®µ
        processed_frame["annotation.human.validity"] = 1
        
        frames_data.append(processed_frame)
    
    return {
        "frames": frames_data,
        "length": episode_length,
        "episode_index": episode_idx,
        "task_info": task_info
    }

def create_videos_from_images(input_dir: Path, output_videos_dir: Path, episode_data: List[Dict], fps: float, code_type: str='h264') -> Dict[str, Tuple[int, int, int]]:
    """ä»å›¾åƒåºåˆ—åˆ›å»ºè§†é¢‘æ–‡ä»¶ï¼Œè¿”å›å›¾åƒå°ºå¯¸å­—å…¸"""
    print("åˆ›å»ºè§†é¢‘æ–‡ä»¶...")
    
    image_shapes = {}  # å­˜å‚¨æ¯ä¸ªè§†è§’çš„å›¾åƒå°ºå¯¸
    
    # ä¸ºæ¯ä¸ªepisodeçš„æ¯ä¸ªè§†è§’åˆ›å»ºè§†é¢‘
    for ep_data in tqdm(episode_data, desc="å¤„ç†è§†é¢‘"):
        episode_idx = ep_data["episode_index"]
        episode_dir = input_dir / f"episode_{episode_idx+1:04d}"
        colors_dir = episode_dir / "colors"
        
        if not colors_dir.exists():
            print(f"è­¦å‘Š: Episode {episode_idx} æ²¡æœ‰colorsç›®å½•ï¼Œè·³è¿‡è§†é¢‘åˆ›å»º")
            continue
        
        # éå†æ‰€æœ‰è§†è§’
        for view_id, view_name in VIEW_MAPPING.items():
            # è·å–è¯¥è§†è§’çš„å›¾åƒæ–‡ä»¶
            image_files = sorted(colors_dir.glob(f"*_color_{view_id}.jpg"))
            if not image_files:
                print(f"è­¦å‘Š: Episode {episode_idx} æ²¡æœ‰{view_name}å›¾åƒï¼Œè·³è¿‡è¯¥è§†è§’")
                continue
            
            # åˆ›å»ºè§†é¢‘è¾“å‡ºç›®å½•
            video_key = f"observation.images.{view_name}"
            video_output_dir = output_videos_dir / "chunk-000" / video_key
            video_output_dir.mkdir(parents=True, exist_ok=True)
            video_path = video_output_dir / f"episode_{episode_idx:06d}.mp4"
            
            # è¯»å–ç¬¬ä¸€å¼ å›¾åƒç¡®å®šå°ºå¯¸
            first_img = cv2.imread(str(image_files[0]))
            if first_img is None:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–å›¾åƒ {image_files[0]}ï¼Œè·³è¿‡{view_name}è§†è§’")
                continue
            
            height, width = first_img.shape[:2]
            image_shapes[video_key] = (3, height, width)  # å­˜å‚¨å°ºå¯¸ä¿¡æ¯
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
            if code_type == 'h264':
                fourcc = cv2.VideoWriter_fourcc(*'avc1') 
            elif code_type == 'mp4v':
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            else:
                fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # é»˜è®¤ä½¿ç”¨mp4v
            
            video_writer = cv2.VideoWriter(str(video_path), fourcc, fps, (width, height))
            
            try:
                for img_path in image_files:
                    img = cv2.imread(str(img_path))
                    if img is not None:
                        video_writer.write(img)
            finally:
                video_writer.release()
            
            print(f"åˆ›å»º {view_name} è§†é¢‘: {video_path}")
    
    return image_shapes

def create_parquet_files(episode_data: List[Dict], output_data_dir: Path):
    """åˆ›å»ºParquetæ•°æ®æ–‡ä»¶"""
    print("åˆ›å»ºParquetæ•°æ®æ–‡ä»¶...")
    
    data_output_dir = output_data_dir / "chunk-000"
    data_output_dir.mkdir(parents=True, exist_ok=True)
    
    all_frames = []
    global_index = 0
    
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        
        for frame in ep_data["frames"]:
            frame_data = frame.copy()
            frame_data["index"] = global_index
            all_frames.append(frame_data)
            global_index += 1
    
    # æŒ‰episodeä¿å­˜æ•°æ®
    for ep_data in episode_data:
        episode_idx = ep_data["episode_index"]
        episode_frames = [f for f in all_frames if f["episode_index"] == episode_idx]
        
        if episode_frames:
            df = pd.DataFrame(episode_frames)
            parquet_path = data_output_dir / f"episode_{episode_idx:06d}.parquet"
            df.to_parquet(parquet_path, index=False)
            print(f"ä¿å­˜æ•°æ®æ–‡ä»¶: {parquet_path}")

def create_metadata_files(episode_data: List[Dict], output_dir: Path, dataset_name: str, robot_type: str, fps: float, image_shapes: Dict[str, Tuple[int, int, int]], code_type: str='h264'):
    """åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶"""
    print("åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶...")
    
    meta_dir = output_dir / "meta"
    meta_dir.mkdir(parents=True, exist_ok=True)
    
    total_episodes = len(episode_data)
    total_frames = sum(ep["length"] for ep in episode_data)
    
    # ä»ç¬¬ä¸€ä¸ªepisodeè·å–æ•°æ®ç»´åº¦ä¿¡æ¯
    if episode_data:
        first_frame = episode_data[0]["frames"][0]
        state_dim = len(first_frame.get("observation.state", []))
        action_dim = len(first_frame.get("action", []))
    else:
        state_dim = action_dim = 7
    
    # åˆ›å»ºinfo.json
    info = {
        "codebase_version": "v2.0",
        "robot_type": robot_type,
        "total_episodes": total_episodes,
        "total_frames": total_frames,
        "total_videos": len(VIEW_MAPPING),  # ä¸‰ç§è§†è§’è§†é¢‘
        "total_chunks": 1,
        "chunks_size": 1000,
        "fps": fps,
        "splits": {"train": f"0:{total_episodes}"},
        "data_path": "data/chunk-{episode_chunk:03d}/episode_{episode_index:06d}.parquet",
        "video_path": "videos/chunk-{episode_chunk:03d}/{video_key}/episode_{episode_index:06d}.mp4",
        "features": {
            "observation.state": {
                "dtype": "float64",
                "shape": [state_dim],
                "names": [f"motor_{i}" for i in range(state_dim)]
            },
            "action": {
                "dtype": "float64", 
                "shape": [action_dim],
                "names": [f"motor_{i}" for i in range(action_dim)]
            },
            "timestamp": {"dtype": "float64", "shape": [1]},
            "annotation.human.action.task_description": {"dtype": "int64", "shape": [1]},
            "task_index": {"dtype": "int64", "shape": [1]},
            "annotation.human.validity": {"dtype": "int64", "shape": [1]},
            "episode_index": {"dtype": "int64", "shape": [1]},
            "index": {"dtype": "int64", "shape": [1]},
            "next.reward": {"dtype": "float64", "shape": [1]},
            "next.done": {"dtype": "bool", "shape": [1]}
        }
    }
    
    # æ·»åŠ ä¸‰ç§è§†é¢‘è§†è§’ç‰¹å¾
    for view_name in VIEW_MAPPING.values():
        video_key = f"observation.images.{view_name}"
        if video_key in image_shapes:
            c, h, w = image_shapes[video_key]
            video_shape = [h, w, c]  # [height, width, channels]
        else:
            # é»˜è®¤å°ºå¯¸
            video_shape = [480, 640, 3]
        
        info["features"][video_key] = {
            "dtype": "video",
            "shape": video_shape,
            "names": ["height", "width", "channel"],
            "video_info": {
                "video.fps": fps,
                "video.codec": code_type,
                "video.pix_fmt": "yuv420p",
                "video.is_depth_map": False,
                "has_audio": False
            }
        }
    
    with open(meta_dir / "info.json", "w") as f:
        json.dump(info, f, indent=2)
    
    # åˆ›å»ºmodality.json
    modality = {
        "state": {
            "left_arm": {"start": 0, "end": 7},
            "right_arm": {"start": 7, "end": 14},
            "left_hand": {"start": 14, "end": 21},
            "right_hand": {"start": 21, "end": 28},
            "left_leg": {"start": 28, "end": 34},
            "right_leg": {"start": 34, "end": 40}
        },
        "action": {
            "left_arm": {"start": 0, "end": 7},
            "right_arm": {"start": 7, "end": 14},
            "left_hand": {"start": 14, "end": 21},
            "right_hand": {"start": 21, "end": 28},
            "base_motion": {"start": 28, "end": 32}
        },
        "video": {
            "ego_view": {"original_key": "observation.images.ego_view"},
            "wrist_left": {"original_key": "observation.images.wrist_left"},
            "wrist_right": {"original_key": "observation.images.wrist_right"}
        },
        "annotation": {
            "human.action.task_description": {},
            "human.validity": {}
        }
    }
    
    with open(meta_dir / "modality.json", "w") as f:
        json.dump(modality, f, indent=4)
    
    # åˆ›å»ºepisodes.jsonl
    with open(meta_dir / "episodes.jsonl", "w") as f:
        for ep_data in episode_data:
            task_info = ep_data.get("task_info", {})
            task_description = task_info.get("goal", f"{dataset_name}_task")
            
            episode_info = {
                "episode_index": ep_data["episode_index"],
                "length": ep_data["length"],
                "tasks": [task_description]
            }
            f.write(json.dumps(episode_info) + "\n")
    
    # åˆ›å»ºtasks.jsonl  
    with open(meta_dir / "tasks.jsonl", "w") as f:
        unique_tasks = set()
        for ep_data in episode_data:
            task_info = ep_data.get("task_info", {})
            task_description = task_info.get("goal", f"{dataset_name}_task")
            unique_tasks.add(task_description)
        
        for idx, task in enumerate(unique_tasks):
            task_info = {"task_index": idx, "task": task}
            f.write(json.dumps(task_info) + "\n")
    
    # åˆ›å»ºepisodes_stats.jsonl
    with open(meta_dir / "episodes_stats.jsonl", "w") as f:
        for ep_data in episode_data:
            episode_idx = ep_data["episode_index"]
            frames = ep_data["frames"]
            
            # æå–observation.stateå’Œactionæ•°æ®
            obs_states = []
            actions = []
            
            for frame in frames:
                if "observation.state" in frame and frame["observation.state"] is not None:
                    obs_state = frame["observation.state"]
                    if isinstance(obs_state, np.ndarray):
                        obs_states.append(obs_state.tolist())
                    elif isinstance(obs_state, dict) and "qpos" in obs_state:
                        obs_states.append(obs_state["qpos"])
                    elif isinstance(obs_state, list):
                        obs_states.append(obs_state)
                if "action" in frame and frame["action"] is not None:
                    action = frame["action"]
                    if isinstance(action, np.ndarray):
                        actions.append(action.tolist())
                    elif isinstance(action, dict) and "qpos" in action:
                        actions.append(action["qpos"])
                    elif isinstance(action, list):
                        actions.append(action)
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            stats = {"episode_index": episode_idx, "stats": {}}
            
            # è®¡ç®—observation.stateç»Ÿè®¡
            if obs_states:
                valid_obs_states = []
                for obs in obs_states:
                    if obs and isinstance(obs, list) and len(obs) > 0:
                        numeric_obs = [float(x) for x in obs if isinstance(x, (int, float))]
                        if numeric_obs:
                            valid_obs_states.append(numeric_obs)
                
                if valid_obs_states:
                    obs_array = np.array(valid_obs_states, dtype=np.float64)
                    stats["stats"]["observation.state"] = {
                        "max": obs_array.max(axis=0).tolist(),
                        "min": obs_array.min(axis=0).tolist(),
                        "mean": obs_array.mean(axis=0).tolist(),
                        "std": obs_array.std(axis=0).tolist()
                    }
                else:
                    stats["stats"]["observation.state"] = {
                        "max": [0.0] * state_dim,
                        "min": [0.0] * state_dim,
                        "mean": [0.0] * state_dim,
                        "std": [0.0] * state_dim
                    }
            else:
                stats["stats"]["observation.state"] = {
                    "max": [0.0] * state_dim,
                    "min": [0.0] * state_dim,
                    "mean": [0.0] * state_dim,
                    "std": [0.0] * state_dim
                }
            
            # è®¡ç®—actionç»Ÿè®¡
            if actions:
                valid_actions = []
                for action in actions:
                    if action and isinstance(action, list) and len(action) > 0:
                        numeric_action = [float(x) for x in action if isinstance(x, (int, float))]
                        if numeric_action:
                            valid_actions.append(numeric_action)
                
                if valid_actions:
                    action_array = np.array(valid_actions, dtype=np.float64)
                    stats["stats"]["action"] = {
                        "max": action_array.max(axis=0).tolist(),
                        "min": action_array.min(axis=0).tolist(),
                        "mean": action_array.mean(axis=0).tolist(),
                        "std": action_array.std(axis=0).tolist()
                    }
                else:
                    stats["stats"]["action"] = {
                        "max": [0.0] * action_dim,
                        "min": [0.0] * action_dim,
                        "mean": [0.0] * action_dim,
                        "std": [0.0] * action_dim
                    }
            else:
                stats["stats"]["action"] = {
                    "max": [0.0] * action_dim,
                    "min": [0.0] * action_dim,
                    "mean": [0.0] * action_dim,
                    "std": [0.0] * action_dim
                }
            
            f.write(json.dumps(stats) + "\n")
    
    print("å…ƒæ•°æ®æ–‡ä»¶åˆ›å»ºå®Œæˆ")

def main():
    parser = argparse.ArgumentParser(description="å°†OpenWBCæ•°æ®é›†è½¬æ¢ä¸ºLeRobotæ ¼å¼ï¼ˆæ”¯æŒå¤šè§†è§’ï¼‰")
    parser.add_argument("--input_dir", type=str, required=True, help="è¾“å…¥æ•°æ®é›†ç›®å½•")
    parser.add_argument("--output_dir", type=str, required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--dataset_name", type=str, required=True, help="æ•°æ®é›†åç§°")
    parser.add_argument("--robot_type", type=str, default="g1", help="æœºå™¨äººç±»å‹")
    parser.add_argument("--fps", type=float, default=30.0, help="è§†é¢‘å¸§ç‡")
    parser.add_argument("--video_enc", type=str, default='h264', help="è§†é¢‘ç¼–ç æ ¼å¼, æ”¯æŒh264æˆ–mp4v")
    parser.add_argument("--filter_file", type=str, default="filter.txt", help="åŒ…å«å…è®¸çš„episodeç¼–å·åˆ—è¡¨çš„æ–‡ä»¶å")
    
    args = parser.parse_args()
    
    input_dir = Path(args.input_dir)
    output_dir = Path(args.output_dir)
    
    if not input_dir.exists():
        print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½episodeè¿‡æ»¤åˆ—è¡¨
    filter_file_path = input_dir / args.filter_file
    filter_episode_numbers = None
    if filter_file_path.exists():
        try:
            with open(filter_file_path, 'r', encoding='utf-8') as f_filter:
                file_content = f_filter.read().strip()
                filter_episode_numbers = ast.literal_eval(file_content)
                if not isinstance(filter_episode_numbers, list) or not all(isinstance(n, int) for n in filter_episode_numbers):
                    print(f"è­¦å‘Š: {filter_file_path} å†…å®¹æ ¼å¼ä¸æ­£ç¡®, å°†å¤„ç†æ‰€æœ‰episode")
                    filter_episode_numbers = None
                else:
                    print(f"ä» {filter_file_path} åŠ è½½äº† {len(filter_episode_numbers)} ä¸ªè¦å¤„ç†çš„episodeç¼–å·")
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–æˆ–è§£æ {filter_file_path} å¤±è´¥: {e}ï¼Œå°†å¤„ç†æ‰€æœ‰episode")
            filter_episode_numbers = None
    
    # è·å–è¦å¤„ç†çš„episodeç›®å½•
    all_potential_episode_dirs = sorted(
        [d for d in input_dir.iterdir() if d.is_dir() and d.name.startswith("episode_")]
    )
    
    episode_dirs_to_process = []
    if filter_episode_numbers is not None:
        for ep_dir in all_potential_episode_dirs:
            try:
                ep_num = int(ep_dir.name.split('_')[-1])
                if ep_num in filter_episode_numbers:
                    episode_dirs_to_process.append(ep_dir)
            except ValueError:
                continue
        print(f"æ ¹æ®è¿‡æ»¤æ–‡ä»¶ï¼Œå°†å¤„ç† {len(episode_dirs_to_process)} ä¸ªepisodes")
    else:
        episode_dirs_to_process = all_potential_episode_dirs
        print(f"å°†å¤„ç†æ‰€æœ‰ {len(episode_dirs_to_process)} ä¸ªepisodes")
    
    if not episode_dirs_to_process:
        print(f"é”™è¯¯: åœ¨ {input_dir} ä¸­æ‰¾ä¸åˆ°ç¬¦åˆæ¡ä»¶çš„episodeç›®å½•")
        return
    
    # æ”¶é›†ä»»åŠ¡ä¿¡æ¯ä»¥åˆ›å»ºtask_map
    print("åˆ†æä»»åŠ¡ä¿¡æ¯...")
    unique_tasks = set()
    for episode_dir in episode_dirs_to_process:
        data_json = episode_dir / "data.json"
        if data_json.exists():
            try:
                episode_data_raw = parse_json_data(data_json)
                task_info = episode_data_raw.get("text", {})
                task_description = task_info.get("goal", "default_task")
                unique_tasks.add(task_description)
            except Exception as e:
                print(f"è­¦å‘Š: è¯»å–episode {episode_dir} çš„ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {e}")
                unique_tasks.add("default_task")
    
    task_map = {task: idx for idx, task in enumerate(sorted(unique_tasks))}
    print(f"å‘ç° {len(task_map)} ä¸ªä¸åŒçš„ä»»åŠ¡")
    
    # è½¬æ¢æ¯ä¸ªepisode
    episode_data = []
    for i, episode_dir in enumerate(tqdm(episode_dirs_to_process, desc="è½¬æ¢episodes")):
        try:
            ep_data = convert_episode(episode_dir, i, output_dir, args.fps, task_map)
            episode_data.append(ep_data)
        except Exception as e:
            print(f"é”™è¯¯: è½¬æ¢episode {episode_dir} å¤±è´¥: {e}")
            continue
    
    if not episode_data:
        print("é”™è¯¯: æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•episode")
        return
    
    # åˆ›å»ºè§†é¢‘æ–‡ä»¶
    videos_dir = output_dir / "videos"
    image_shapes = create_videos_from_images(input_dir, videos_dir, episode_data, args.fps, code_type=args.video_enc)
    
    # åˆ›å»ºParquetæ•°æ®æ–‡ä»¶  
    data_dir = output_dir / "data"
    create_parquet_files(episode_data, data_dir)
    
    # åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    create_metadata_files(episode_data, output_dir, args.dataset_name, args.robot_type, args.fps, image_shapes, code_type=args.video_enc)
    
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š è½¬æ¢äº† {len(episode_data)} ä¸ªepisodes")
    print(f"ğŸ¬ æ€»å¸§æ•°: {sum(ep['length'] for ep in episode_data)}")
    print(f"ğŸ“· æ”¯æŒçš„è§†è§’: {list(VIEW_MAPPING.values())}")
    
    print(f"\nğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
    print(f"from lerobot.common.datasets.lerobot_dataset import LeRobotDataset")
    print(f"dataset = LeRobotDataset('{output_dir}')")
    print(f"print(f'æ•°æ®é›†å¤§å°: {{len(dataset)}}')")

if __name__ == "__main__":
    main()